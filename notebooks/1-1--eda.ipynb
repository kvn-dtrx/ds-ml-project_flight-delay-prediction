{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry_convert as pc\n",
    "import ppscore as pps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from local_nbutils import CFG, plt_savefig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Confrontation with the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the data from file into a pandas data frame and create a copy that will incorporate our manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CFG[\"TRAIN_DATA_PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual initial inspection commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning of column names (according to <https://zindi.africa/competitions/flight-delay-prediction-challenge/data>):\n",
    "\n",
    "Present in the data:\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| ID | Unique identifier for the flight |\n",
    "| DATOP | Date of flight |\n",
    "| FLTID | Flight number |\n",
    "| DEPSTN | Departure point (station/airport) |\n",
    "| ARRSTN | Arrival point (station/airport) |\n",
    "| STD | Scheduled Time of Departure |\n",
    "| STA | Scheduled Time of Arrival |\n",
    "| STATUS | Flight status (e.g., delayed, canceled) |\n",
    "| AC | Aircraft code |\n",
    "| target | Flight delay (in minutes) |\n",
    "\n",
    "\n",
    "Not present in the data (although claimed on the referenced web page):\n",
    "\n",
    "| Column | Description |\n",
    "| --- | --- |\n",
    "| ETD | Expected Time departure |\n",
    "| ETA | Expected Time arrival |\n",
    "| ATD | Actual Time of Departure |\n",
    "| ATA | Actual Time of arrival |\n",
    "| DELAY1 | Delay code 1 |\n",
    "| DUR1 | Delay time 1 |\n",
    "| DELAY2 | Delay code 2 |\n",
    "| DUR2 | Delay time 2 |\n",
    "| DELAY3 | Delay code 3 |\n",
    "| DUR3 | Delay time 3 |\n",
    "| DELAY4 | Delay code 4 |\n",
    "| DUR4 | Delay time 4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorry for \"statuses\" ...\n",
    "statuses = df[\"STATUS\"].unique()\n",
    "\n",
    "print(\"All Statuses:\")\n",
    "for status in statuses:\n",
    "    print(f\"  {status}\")\n",
    "    print(f\"    Number of entries: {df[df['STATUS'] == status].shape[0]}\")\n",
    "    print(f\"    Mean: {df[df['STATUS'] == status]['target'].mean()}\")\n",
    "    print(f\"    Median: {df[df['STATUS'] == status]['target'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Code | Name | Description |\n",
    "| --- | --- | --- |\n",
    "| ATA | Actual Time Arrival| Flights that successfully landed at their destination |\n",
    "| DEP  | Departed | Flights that departed but may not have completed their journey |\n",
    "| RTR  | Returned | Flights that took off but returned to the departure airport due to issues |\n",
    "| SCH  | Scheduled | Flights listed in the schedule, no delay data applicable |\n",
    "| DEL  | Canceled | Flights that were canceled, treated as permanent delays |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, status in enumerate(statuses):\n",
    "    ax = axes[idx]\n",
    "    df[df[\"STATUS\"] == status][\"target\"].hist(\n",
    "        bins=50,\n",
    "        log=False,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(status)\n",
    "    ax.set_xlabel(\"Delay\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt_savefig(\"delay-to-sum-flight-histograms\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpretation of DEP remains a bit obscure ... in a first approximation, we drop it. Further, it is hard to measure the delay of a DEL flight (a possibility for regular flights would be to take the duration between the DEL flight and the next flight that indeed arrives plus the delay of that flight). But we also decide us simply for dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"STATUS\"].isin([\"DEP\", \"DEL\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airport Columns\n",
    "\n",
    "We introduce columns reducing the airports of departure and destination to its country, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv(CFG[\"AIRPORTS_DATA_PATH\"])\n",
    "airports = airports[[\"iata_code\", \"iso_country\"]]\n",
    "airports = airports.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bkp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Make this cell idempotent\n",
    "\n",
    "df = df_bkp.merge(\n",
    "    airports[[\"iata_code\", \"iso_country\"]],\n",
    "    left_on=\"DEPSTN\",\n",
    "    right_on=\"iata_code\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df.drop(columns=\"iata_code\", inplace=True)\n",
    "df.rename(columns={\"iso_country\": \"country_dep\"}, inplace=True)\n",
    "\n",
    "df = df.merge(\n",
    "    airports[[\"iata_code\", \"iso_country\"]],\n",
    "    left_on=\"ARRSTN\",\n",
    "    right_on=\"iata_code\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df.drop(columns=\"iata_code\", inplace=True)\n",
    "df.rename(columns={\"iso_country\": \"country_arr\"}, inplace=True)\n",
    "\n",
    "df[\"country_arr\"].shape\n",
    "\n",
    "df.loc[df[\"DEPSTN\"] == \"SXF\", \"country_dep\"] = \"DE\"\n",
    "df.loc[df[\"ARRSTN\"] == \"SXF\", \"country_arr\"] = \"DE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For converting the iso codes to continent codes, we use the functionality provided by the module `pycountry_convert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_to_continent(iso: str) -> None | str:\n",
    "    try:\n",
    "        continent_code = pc.country_alpha2_to_continent_code(iso)\n",
    "        return pc.convert_continent_code_to_continent_name(continent_code)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "df[\"continent_dep\"] = df[\"country_dep\"].apply(iso_to_continent)\n",
    "df[\"continent_arr\"] = df[\"country_arr\"].apply(iso_to_continent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dating issues\n",
    "\n",
    "The data set contains several columns with date semantics. Let us convert them to the appropriate dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATOP\"] = pd.to_datetime(df[\"DATOP\"], format=\"%Y-%m-%d\")\n",
    "df[\"STD\"] = pd.to_datetime(df[\"STD\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"STA\"] = pd.to_datetime(df[\"STA\"], format=\"%Y-%m-%d %H.%M.%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can introduce a bunch of further useful date and time related columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATOP_year\"] = df[\"DATOP\"].dt.year\n",
    "df[\"DATOP_month\"] = df[\"DATOP\"].dt.month\n",
    "df[\"DATOP_day\"] = df[\"DATOP\"].dt.dayofweek + 1\n",
    "\n",
    "def map_hour_to_period(hour: int) -> str:\n",
    "    if 6 <= hour < 12:\n",
    "        return \"morning\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"day\"\n",
    "    elif 18 <= hour < 24:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "\n",
    "df[\"STD_hour\"] = df[\"STD\"].dt.hour\n",
    "df[\"STD_period\"] = df[\"STD_hour\"].apply(map_hour_to_period)\n",
    "\n",
    "df[\"flight_time\"] = (df[\"STA\"] - df[\"STD\"]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which years are actually present?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOP_years = df[\"DATOP_year\"].unique()\n",
    "DATOP_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the data are from the years 2016, 2017, 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=len(DATOP_years), figsize=(16, 5), sharey=True)\n",
    "\n",
    "for idx, year in enumerate(DATOP_years):\n",
    "    # Filter the DataFrame for the specific year\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    \n",
    "    # Plot the histogram on the respective subplot\n",
    "    axes[idx].hist(df_year[\"DATOP_month\"], bins=range(1, 14), alpha=0.8, color=\"blue\")\n",
    "    axes[idx].set_title(f\"Flight Distribution for {year}\")\n",
    "    axes[idx].set_xlabel(\"Month\")\n",
    "    axes[idx].set_xticks(range(1, 13))  # Set x-axis ticks for months\n",
    "    axes[idx].set_ylabel(\"Number of Flights\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt_savefig(\"month-to-sum-flight-by-year_hist.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each year, we find a suspicious months in which the sum of flights is significantly less than in the others. Looking at the provided test data set one sees that the majority of flights for the affected months can be found there (sic!) ... We drop these months completely: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df[\"DATOP_month\"] == 5) & (df[\"DATOP_year\"] == 2016))]\n",
    "df = df[~((df[\"DATOP_month\"] == 2) & (df[\"DATOP_year\"] == 2017))]\n",
    "df = df[~((df[\"DATOP_month\"] == 9) & (df[\"DATOP_year\"] == 2018))]\n",
    "\n",
    "df = df[df[\"DEPSTN\"] != df[\"ARRSTN\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df[\"flight_time\"], df[\"target\"], color=\"blue\")\n",
    "plt.xlabel(\"Flight Time\")\n",
    "plt.ylabel(\"Delay\")\n",
    "plt.xlim(1,3000)\n",
    "plt.ylim(1,3000)\n",
    "plt.title(\"Scatter Plot of X Column vs Y Column\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_years = len(DATOP_years)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, year in enumerate(DATOP_years):\n",
    "    ax = axes[i]  # Access subplot\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    daily_avg = df_year.groupby(\"DATOP_day\")[\"target\"].mean().reset_index()\n",
    "    \n",
    "    # Plot bar plot on the current subplot\n",
    "    ax.bar(daily_avg[\"DATOP_day\"], daily_avg[\"target\"], color=\"blue\", alpha=0.7)\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title(f\"Average Delay by Day of Week for {year}\", fontsize=12)\n",
    "    ax.set_xlabel(\"Month\", fontsize=10)\n",
    "    ax.set_ylabel(\"Delay\", fontsize=10)\n",
    "    ax.set_xticks(range(1, 8)) \n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt_savefig(\"month-to-avg-delay-by-year_hist\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Look at the Brushed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot gives a feeling for single and pairwise distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "\n",
    "plt_savefig(\"each-vs-each-wrt-distribution_scatterplot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the correlation matrix is never a bad idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot the correlation matrix as a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "\n",
    "plt_savefig(\"each-vs-each-wrt-correlation_heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But as we have so many categorical features, it makes sense to compute the power predictive score (pps) matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    col \n",
    "    for col in df.columns\n",
    "    if not col.startswith(\"DATOP_\") and col not in [\"ID\"]\n",
    "]\n",
    "\n",
    "df_tmp = df[cols]\n",
    "\n",
    "pp_scores = pps.matrix(df_tmp)[[\"x\", \"y\", \"ppscore\"]].pivot(\n",
    "    columns=\"x\", index=\"y\", values=\"ppscore\"\n",
    ")\n",
    "\n",
    "pp_scores = pp_scores.round(2)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "sns.heatmap(\n",
    "    pp_scores,\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    # cmap=\"Reds\",\n",
    "    linewidths=0.5,\n",
    "    annot=True,\n",
    ")\n",
    "\n",
    "plt_savefig(\"each-vs-each-wrt-pp-score_heatmap\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(CFG[\"PROCESSED_DATA_PATH\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
