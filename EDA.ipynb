{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import missingno as msno\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Power predictive score\n",
    "import ppscore as pps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_TRAIN = \"./data/train.csv\"\n",
    "\n",
    "RSEED = 42\n",
    "DPI = 600\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.isnull().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"STATUS\"].unique())\n",
    "\n",
    "col_entries = [\"ATA\", \"DEP\", \"RTR\", \"SCH\", \"DEL\"]\n",
    "\n",
    "for year in col_entries:\n",
    "    print(f\"Number of entries of {year}: {df[df['STATUS'] == year].shape[0]}\")\n",
    "    print(f\"Mean: {df[df['STATUS'] == year]['target'].mean()}\")\n",
    "    print(f\"Median: {df[df['STATUS'] == year]['target'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"STA\"] = df[\"STA\"].str.replace(\".\", \":\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATOP\"] = pd.to_datetime(df[\"DATOP\"], format=\"%Y-%m-%d\")\n",
    "df[\"STD\"] = pd.to_datetime(df[\"STD\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"STA\"] = pd.to_datetime(df[\"STA\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year, month, dayofweek and hour information out of column publish_time and build new column for each\n",
    "df[\"DATOP_year\"]=df[\"DATOP\"].dt.year\n",
    "df[\"DATOP_month\"]=df[\"DATOP\"].dt.month\n",
    "df[\"DATOP_day\"]=df[\"DATOP\"].dt.dayofweek+1\n",
    "#df[\"publish_hour\"]=df[\"publish_time\"].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"flight_time\"] = (df[\"STA\"] - df[\"STD\"]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"STATUS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "# df[\"DEPSTN\"].nunique()\n",
    "# df[\"ARRSTN\"].nunique()\n",
    "# pps.matrix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_scores = pps.matrix(df)[[\"x\", \"y\", \"ppscore\"]].pivot(\n",
    "    columns=\"x\", index=\"y\", values=\"ppscore\"\n",
    ")\n",
    "pp_scores = pp_scores.round(2)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pp_scores, vmin=0, vmax=1, cmap=\"Reds\", linewidths=0.5, annot=True)\n",
    "\n",
    "\n",
    "plt.savefig(\"./img/pp-scores.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df)\n",
    "\n",
    "plt.savefig(\"./img/pairplot.png\", dpi=DPI, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOP_years = df[\"DATOP_year\"].unique()\n",
    "\n",
    "for year in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    df_year[\"DATOP_month\"].hist(bins=12)\n",
    "    plt.title(f\"Flight Distribution per Month â€“ {year}\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"Number of Flights\")\n",
    "    plt.xticks(range(1, 13))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in DATOP_years:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    df_year = df[df[\"DATOP_year\"] == year]\n",
    "    df_year.groupby(\"DATOP_month\")[\"target\"].sum().plot(\n",
    "        kind=\"line\",\n",
    "        title=f\"Monthly Sum of Target for {year}\",\n",
    "        xlabel=\"Month\",\n",
    "        ylabel=\"Sum of Target\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model (a.k.a. a Feeble Try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['AC'], prefix='AC')\n",
    "\n",
    "y = df.target\n",
    "X = df_encoded.drop(\"target\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RSEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df_encoded.columns if col.startswith(\"AC_\")]\n",
    "\n",
    "X_0 = X_train[cols]\n",
    "y_0 = y_train\n",
    "X_1 = X_test[cols]\n",
    "y_1 = y_test\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [\n",
    "        3,\n",
    "        # 5, 7, 9\n",
    "    ],\n",
    "    \"weights\": [\"uniform\", \"distance\"],  # Weighting scheme\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"],  # Distance metric\n",
    "}\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, param_grid=param_grid, cv=5, scoring=\"neg_mean_squared_error\"\n",
    ")\n",
    "\n",
    "# Fit the grid search to training data\n",
    "grid_search.fit(X_0, y_0)\n",
    "\n",
    "\n",
    "# # model = LinearRegression()\n",
    "# model = KNeighborsRegressor(n_neighbors=500)\n",
    "\n",
    "# model.fit(X_0, y_0)\n",
    "\n",
    "y_pred = model.predict(X_1)\n",
    "\n",
    "mse = mean_squared_error(y_1, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_1, y_pred)\n",
    "\n",
    "# Display results\n",
    "# print(\"Coefficients:\", linreg.coef_)\n",
    "# print(\"Intercept:\", model.intercept_)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "# print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaningin and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this exercise we will only deal with numeric variables\n",
    "\n",
    "X = coffee_features.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Quakers column and unnamed\n",
    "#changing one of the altitude to log and droping the original\n",
    "X_train[\"altitude_mean_log\"] = np.log(X_train[\"altitude_mean_meters\"])\n",
    "X_train.drop(['altitude_mean_meters'], axis=1, inplace=True)\n",
    "X_train.drop(['Quakers'], axis=1, inplace=True)\n",
    "X_train.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altitude_low_meters_mean = X_train[\"altitude_low_meters\"].mean()\n",
    "altitude_high_meters_mean = X_train[\"altitude_high_meters\"].mean()\n",
    "altitude_mean_log_mean = X_train[\"altitude_mean_log\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna with mean.. \n",
    "X_train[\"altitude_low_meters\"] = X_train[\"altitude_low_meters\"].fillna(altitude_low_meters_mean)\n",
    "X_train[\"altitude_high_meters\"] = X_train[\"altitude_high_meters\"].fillna(altitude_high_meters_mean)\n",
    "X_train[\"altitude_mean_log\"] = X_train[\"altitude_mean_log\"].fillna(altitude_mean_log_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"altitude low meters mean is {altitude_low_meters_mean}\")\n",
    "print(f\"altitude_high_meters_mean is {altitude_high_meters_mean}\")\n",
    "print(f\"altitude_mean_log_mean is {altitude_mean_log_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in order to exemplify how the predict will work.. we will save the y_train\n",
    "X_test.to_csv(\"data/X_test.csv\")\n",
    "y_test.to_csv(\"data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_train_pred = reg.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_train_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping Quakers column and unnamed\n",
    "#changing one of the altitude to log and droping the original\n",
    "X_test[\"altitude_mean_log\"] = np.log(X_test[\"altitude_mean_meters\"])\n",
    "X_test.drop(['altitude_mean_meters'], axis=1, inplace=True)\n",
    "X_test.drop(['Quakers'], axis=1, inplace=True)\n",
    "X_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# fillna with mean.. \n",
    "X_test[\"altitude_low_meters\"] = X_test[\"altitude_low_meters\"].fillna(altitude_low_meters_mean)\n",
    "X_test[\"altitude_high_meters\"] = X_test[\"altitude_high_meters\"].fillna(altitude_high_meters_mean)\n",
    "X_test[\"altitude_mean_log\"] = X_test[\"altitude_mean_log\"].fillna(altitude_mean_log_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
